{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "disaster_tweets.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "pBMSJz6vV1QC",
        "colab_type": "code",
        "outputId": "beeffd9d-c521-4123-d630-3343d4e186f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfN8FyP2bez3",
        "colab_type": "code",
        "outputId": "ee289e49-3984-4cbc-eeb6-8f8d803edf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UEMGwHXV1QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device('cuda:0')\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    \n",
        "try:\n",
        "    from google.colab import drive\n",
        "    is_in_colab = True\n",
        "except:\n",
        "    is_in_colab = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2YBaxUFV1QJ",
        "colab_type": "code",
        "outputId": "9912111d-9da5-456a-b92d-077590d92d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    is_in_colab = True\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "except:\n",
        "    is_in_colab = False\n",
        "\n",
        "if is_in_colab:\n",
        "    drive.mount('/content/drive')\n",
        "    data_folder = r'/content/drive/My Drive/Colab/Real-or-Not/data/'\n",
        "else:\n",
        "    data_folder = r'./data/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoxsIQ1WV1QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "data = pd.read_csv(data_folder + '/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDy8DVN4V1QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "szPOVa9jV1QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XNa-eVSIV1QW",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WVFJbkUV1QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hashtag_column(dataframe):\n",
        "    hashtags = []\n",
        "    for text in dataframe.text:\n",
        "        result = re.findall('#\\w+', text)\n",
        "        if result != []:\n",
        "            result = [w[1:].lower() for w in result]\n",
        "            hashtags.append(' '.join(result))\n",
        "    return hashtags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "CprzzdlxV1Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize_texts(texts):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    result = []\n",
        "    for t in texts:\n",
        "        lemmatized_words = []\n",
        "        t = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
        "                  'url', t)\n",
        "        #t = re.sub('\\!+', '', t)\n",
        "        #t = re.sub('\\?+', '', t)\n",
        "        #t = re.sub('\\d+[\\:|\\.]?\\d*\\s')\n",
        "#         t = re.sub('\\d+', '', t)\n",
        "        tokens = re.findall('''\\d+,?.?\\d+|\\w+'\\w+|#?\\w+-?\\w+|\\w+\\*+\\w+''', t)\n",
        "        if tokens == []:\n",
        "            print('No tokens for text:\\n', t)\n",
        "        \n",
        "        #tokens = [w.lower() for w in tokens]\n",
        "        for token in tokens:\n",
        "            if token.lower() not in stop_words:\n",
        "                lemmatized_words.append(lemmatizer.lemmatize(token).lower())\n",
        "        result.append(' '.join(lemmatized_words).replace('#', ''))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyDaWJn5V1Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "    return text.split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urgH35s4V1Qk",
        "colab_type": "code",
        "outputId": "ff66d498-2c92-4d9c-980f-6aa7f80b8ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tweets = lemmatize_texts(data.text)\n",
        "all_lemmatized_tokens = [w for t in tweets for w in t.split(' ')]\n",
        "print('Total words: ', len(all_lemmatized_tokens))\n",
        "print('Unique_words: ', len(set(all_lemmatized_tokens)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words:  73941\n",
            "Unique_words:  16624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOcVaH7wV1Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Most common words in dataset\n",
        "freq = nltk.probability.FreqDist(all_lemmatized_tokens)\n",
        "# freq.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1fCcUBMV1Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Most common words in real tweets\n",
        "real_tweets = data[data.target == 1].text\n",
        "real_tweets = lemmatize_texts(real_tweets)\n",
        "freq_real = nltk.probability.FreqDist([w for t in real_tweets for w in t.split(' ')])\n",
        "# freq_real.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT5GNP_-V1Qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Most common words in fake tweets\n",
        "fake_tweets = data[data.target == 0].text\n",
        "fake_tweets = lemmatize_texts(fake_tweets)\n",
        "freq_fake = nltk.probability.FreqDist([w for t in fake_tweets for w in t.split(' ')])\n",
        "# freq_fake.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaSP7SwJV1Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(tweets, data.target, train_size = 0.8, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "V9mYqV6KV1RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorize texts\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2), tokenizer=tokenizer)\n",
        "train = vectorizer.fit_transform(X_train)\n",
        "val = vectorizer.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zcafxVPuV1RF",
        "colab_type": "text"
      },
      "source": [
        "# Classic models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fVigEZaYV1RG",
        "colab_type": "text"
      },
      "source": [
        "## LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "gLVcDO7ZV1RH",
        "colab_type": "code",
        "outputId": "1a146eb6-38be-471a-a66c-884d385a6fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "svc = LinearSVC(random_state=42, C=1, penalty='l2', dual=False, max_iter=1000)\n",
        "svc.fit(train, y_train)\n",
        "svc.score(val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7859487852921865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3Ip3QWpbV1RJ",
        "colab_type": "text"
      },
      "source": [
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "ZfQpWVrSV1RK",
        "colab_type": "code",
        "outputId": "15416590-8d26-44bc-84c2-eb8122e6b005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "forest = RandomForestClassifier(random_state=42, \n",
        "                                n_estimators=500, \n",
        "                                min_samples_leaf=1, \n",
        "                                max_depth=500,\n",
        "                                oob_score=True)\n",
        "\n",
        "forest.fit(train, y_train)\n",
        "print(forest.oob_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7865353037766831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "c2V9xU77V1RM",
        "colab_type": "code",
        "outputId": "f3b9a2e4-a2c2-41fe-faae-d73a3107dbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "forest.score(val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7820091923834537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "737rPOSvV1RP",
        "colab_type": "code",
        "outputId": "6a95446e-261a-431f-b044-9d3748204ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "importance = sorted(zip(vectorizer.get_feature_names(), forest.feature_importances_), key=lambda x: x[1], reverse=True)\n",
        "for imp in importance[:20]: print(\"Feature '{}', importance={}\".format(*imp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature 'url', importance=0.01778135697535768\n",
            "Feature 'fire', importance=0.007216360137181047\n",
            "Feature 'hiroshima', importance=0.006028989100168835\n",
            "Feature 'california', importance=0.004819121060211772\n",
            "Feature 'killed', importance=0.004386780481565708\n",
            "Feature 'suicide', importance=0.0037768614321520007\n",
            "Feature 'wildfire', importance=0.0035834106387096143\n",
            "Feature 'storm', importance=0.0034789825363804186\n",
            "Feature 'bombing', importance=0.003337123193101085\n",
            "Feature 'earthquake', importance=0.0032461968407560557\n",
            "Feature 'train', importance=0.0028747654752379406\n",
            "Feature 'mh370', importance=0.002562752132686677\n",
            "Feature 'police', importance=0.002561265136058398\n",
            "Feature 'massacre', importance=0.0024027737726525483\n",
            "Feature 'japan', importance=0.002287234156945054\n",
            "Feature 'drought', importance=0.0022617893703801447\n",
            "Feature 'accident', importance=0.0022141630229249223\n",
            "Feature 'atomic', importance=0.0021913164242427976\n",
            "Feature 'evacuated', importance=0.0021098341392674393\n",
            "Feature 'car', importance=0.0020397573801108513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uGbULnbtV1RS",
        "colab_type": "text"
      },
      "source": [
        "## AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "YqY-wNdzV1RS",
        "colab_type": "code",
        "outputId": "4214c56a-1a7c-4638-a0c4-42a300eb6c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "boost = AdaBoostClassifier(base_estimator=LogisticRegression(), random_state=42,\n",
        "                           n_estimators=2000, learning_rate=1)\n",
        "boost.fit(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                     dual=False,\n",
              "                                                     fit_intercept=True,\n",
              "                                                     intercept_scaling=1,\n",
              "                                                     l1_ratio=None,\n",
              "                                                     max_iter=100,\n",
              "                                                     multi_class='auto',\n",
              "                                                     n_jobs=None, penalty='l2',\n",
              "                                                     random_state=None,\n",
              "                                                     solver='lbfgs', tol=0.0001,\n",
              "                                                     verbose=0,\n",
              "                                                     warm_start=False),\n",
              "                   learning_rate=1, n_estimators=2000, random_state=42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "i92DifN7V1RV",
        "colab_type": "code",
        "outputId": "7fb19f21-2264-4045-d5b5-fdb254d04233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "boost.score(val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7997373604727511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YUMUKYXlV1RX",
        "colab_type": "text"
      },
      "source": [
        "## BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "X2Um4fIbV1RY",
        "colab_type": "code",
        "outputId": "cf045d47-a372-4e6b-af6d-6dbbf99b0474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "bagging = BaggingClassifier(base_estimator = LogisticRegression(), random_state=42,  \n",
        "                            max_features=0.7, n_jobs=-1, \n",
        "                            max_samples=1.0, n_estimators=2000)\n",
        "bagging.fit(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                    dual=False,\n",
              "                                                    fit_intercept=True,\n",
              "                                                    intercept_scaling=1,\n",
              "                                                    l1_ratio=None, max_iter=100,\n",
              "                                                    multi_class='auto',\n",
              "                                                    n_jobs=None, penalty='l2',\n",
              "                                                    random_state=None,\n",
              "                                                    solver='lbfgs', tol=0.0001,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                  bootstrap=True, bootstrap_features=False, max_features=0.7,\n",
              "                  max_samples=1.0, n_estimators=2000, n_jobs=-1,\n",
              "                  oob_score=False, random_state=42, verbose=0,\n",
              "                  warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "piA_DeFlV1Rb",
        "colab_type": "code",
        "outputId": "2bcb24b2-d050-40b4-d158-2020d401c44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bagging.score(val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8082731451083388"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7p5aufh8V1Re",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PrmMt9irV1Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device('cuda:0')\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    from torch import FloatTensor, LongTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "8b8PeuBQV1Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, loss_function, train_data=None, val_data=None, optimizer=None,\n",
        "        epoch_count=1, batch_size=1, scheduler=None, alpha=1, bert=False):\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    best_model = None\n",
        "    for epoch in range(epoch_count):\n",
        "            name_prefix = '[{} / {}] '.format(epoch + 1, epoch_count)\n",
        "            epoch_train_score = 0\n",
        "            epoch_val_score = 0\n",
        "            \n",
        "            if train_data:\n",
        "                epoch_train_score = do_epoch(model, loss_function, train_data, batch_size, \n",
        "                                              optimizer, name_prefix + 'Train:', alpha=alpha, bert=bert,\n",
        "                                             scheduler=scheduler)\n",
        "                train_history.append(epoch_train_score)\n",
        "\n",
        "            if val_data:\n",
        "                name = '  Val:'\n",
        "                if not train_data:\n",
        "                    name = ' Test:'\n",
        "                epoch_val_score = do_epoch(model, loss_function, val_data, batch_size, \n",
        "                                             optimizer=None, name=name_prefix + name, alpha=alpha, bert=bert,\n",
        "                                           scheduler=scheduler)\n",
        "                \n",
        "                val_history.append(epoch_val_score)\n",
        "\n",
        "    return train_history, val_history\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "hmaj7gvAV1Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_epoch(model, loss_function, data, batch_size, optimizer=None, name=None, alpha=1, bert=False, scheduler=None):\n",
        "    \"\"\"\n",
        "       Генерация одной эпохи\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    epoch_loss = 0\n",
        "   \n",
        "    batch_count = len(data)\n",
        "   \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batch_count) as progress_bar:               \n",
        "            for ind, batch in enumerate(data):\n",
        "                if bert:\n",
        "                  X_batch, X_mask, y_batch =  batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "                  loss, prediction = model(X_batch, token_type_ids=None, attention_mask=X_mask, labels=y_batch)\n",
        "                else:\n",
        "                  X_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
        "                  prediction = model(X_batch)\n",
        "                  loss = loss_function(prediction, y_batch)\n",
        "\n",
        "                  for param in model.children():\n",
        "                    if type(param) == nn.Linear:\n",
        "                        loss += alpha * torch.abs(param.weight).sum()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                true_indices = torch.argmax(prediction, dim=1)\n",
        "                correct_samples = torch.sum(true_indices == y_batch).cpu().numpy()\n",
        "                accuracy += correct_samples / y_batch.shape[0]\n",
        "\n",
        "                if is_train:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    if scheduler: scheduler.step(accuracy)\n",
        "              \n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('Epoch {} - accuracy: {:.2f}, loss {:.2f}'.format(\n",
        "                    name, (accuracy / (ind+1)), epoch_loss / (ind+1))\n",
        "                )\n",
        "            \n",
        "            accuracy /= (ind + 1)\n",
        "            epoch_loss /= (ind + 1) \n",
        "            progress_bar.set_description(f'Epoch {name} - accuracy: {accuracy:.2f}, loss: {epoch_loss:.2f}')\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWXCaG_FavJw",
        "colab_type": "text"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arS06iCpa0eX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing data\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4qhTfS0Nx0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_for_bert(texts):\n",
        "  MAX_LEN = 0\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for tweet in texts:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_tweet = bert_tokenizer.encode(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "    if len(encoded_tweet) > MAX_LEN:\n",
        "      MAX_LEN = len(encoded_tweet)\n",
        "\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                        value=0, truncating=\"post\", padding=\"post\")\n",
        "  \n",
        "  # Make attention masks token -> 1, [PAD] -> 0\n",
        "  for tweet in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "    attention_masks.append(att_mask)\n",
        "    \n",
        "  return input_ids, attention_masks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21twlXWlT6F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids, attention_masks = prepare_data_for_bert(tweets)\n",
        "labels = data.target.values\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.25)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.25)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmJOeMW_dbao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(torch.tensor(train_inputs), torch.tensor(train_masks), torch.tensor(train_labels))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(torch.tensor(validation_inputs), torch.tensor(validation_masks), torch.tensor(validation_labels))\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ua76ZZAdvFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "\n",
        "bert = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "bert.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nng3mn4hhEyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# AdamW is a class from the huggingface library\n",
        "optimizer = AdamW(bert.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-2-mBvvnpFX",
        "colab_type": "code",
        "outputId": "666fc797-d69e-426d-b446-05cb0d896859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "train_history_bert, val_history_ bert = fit(model, loss_function=None, train_data=train_dataloader, val_data=validation_dataloader, optimizer=optimizer, epoch_count=3, batch_size=32, scheduler=scheduler, alpha=1, bert=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1 / 3] Train: - accuracy: 0.78, loss: 0.48: 100%|██████████| 357/357 [01:30<00:00,  4.20it/s]\n",
            "Epoch [1 / 3]   Val: - accuracy: 0.81, loss: 0.43: 100%|██████████| 119/119 [00:08<00:00, 14.56it/s]\n",
            "Epoch [2 / 3] Train: - accuracy: 0.84, loss: 0.40: 100%|██████████| 357/357 [01:29<00:00,  4.18it/s]\n",
            "Epoch [2 / 3]   Val: - accuracy: 0.82, loss: 0.44: 100%|██████████| 119/119 [00:08<00:00, 14.51it/s]\n",
            "Epoch [3 / 3] Train: - accuracy: 0.86, loss: 0.35: 100%|██████████| 357/357 [01:29<00:00,  4.18it/s]\n",
            "Epoch [3 / 3]   Val: - accuracy: 0.83, loss: 0.43: 100%|██████████| 119/119 [00:08<00:00, 14.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.7777149321266968, 0.8355284421460892, 0.8612233354880414],\n",
              " [0.8067226890756303, 0.8151260504201681, 0.8261554621848739])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CXB0QbfsV1Rz",
        "colab_type": "text"
      },
      "source": [
        "## LinearNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "6IyfovsBV1R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNModel():\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        \n",
        "    def predict(self, inputs):\n",
        "        self.model.eval()\n",
        "        output = pd.DataFrame()\n",
        "        for ind in range(inputs.shape[0]):\n",
        "            X = FloatTensor(inputs[ind].toarray())\n",
        "            predict = self.model(X)\n",
        "            true_indices = torch.argmax(predict, dim=1).detach().cpu().numpy()\n",
        "            output.loc[ind, 'target'] = true_indices\n",
        "        return output.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "OaauF8d3V1R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit settings\n",
        "batch_size = 100\n",
        "epoch_count = 10\n",
        "\n",
        "# optim settings\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 0.1\n",
        "alpha = 0.005\n",
        "\n",
        "# model settings\n",
        "linear1_out = int(train.shape[1]**0.5)\n",
        "output = 2\n",
        "dropout = 0.3\n",
        "\n",
        "# scheduler settings\n",
        "factor = 0.5\n",
        "patience = 3\n",
        "threshold = 1e-2\n",
        "\n",
        "model = nn.Sequential(nn.Linear(train.shape[1], linear1_out),\n",
        "                      nn.BatchNorm1d(linear1_out),\n",
        "#                       nn.Dropout(p=dropout, inplace=True),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                      nn.Linear(linear1_out, output),\n",
        "                      nn.ReLU(inplace=True)\n",
        "                     ).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "                        model.parameters(),\n",
        "                        lr=learning_rate, \n",
        "                        weight_decay=weight_decay\n",
        "                    )\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=factor, \n",
        "                              patience=patience, verbose=True, threshold=threshold\n",
        "                              )\n",
        "\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(torch.FloatTensor(train.toarray()), torch.tensor(np.array(y_train)))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(torch.FloatTensor(val.toarray()), torch.tensor(np.array(y_val)))\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WHOHn2xlGcv",
        "colab_type": "code",
        "outputId": "2e68cb74-094a-4b32-ae98-28633237df35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "fit(model, loss_function, train_dataloader, validation_dataloader, optimizer, epoch_count, 100, scheduler=None, alpha=alpha)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1 / 10] Train: - accuracy: 0.61, loss: 38.18: 100%|██████████| 61/61 [00:01<00:00, 47.94it/s]\n",
            "Epoch [1 / 10]   Val: - accuracy: 0.67, loss: 3.85: 100%|██████████| 16/16 [00:00<00:00, 59.10it/s]\n",
            "Epoch [2 / 10] Train: - accuracy: 0.71, loss: 2.48: 100%|██████████| 61/61 [00:01<00:00, 48.58it/s]\n",
            "Epoch [2 / 10]   Val: - accuracy: 0.78, loss: 2.32: 100%|██████████| 16/16 [00:00<00:00, 57.20it/s]\n",
            "Epoch [3 / 10] Train: - accuracy: 0.79, loss: 2.30: 100%|██████████| 61/61 [00:01<00:00, 48.15it/s]\n",
            "Epoch [3 / 10]   Val: - accuracy: 0.79, loss: 2.44: 100%|██████████| 16/16 [00:00<00:00, 59.25it/s]\n",
            "Epoch [4 / 10] Train: - accuracy: 0.81, loss: 2.31: 100%|██████████| 61/61 [00:01<00:00, 48.41it/s]\n",
            "Epoch [4 / 10]   Val: - accuracy: 0.79, loss: 2.46: 100%|██████████| 16/16 [00:00<00:00, 59.95it/s]\n",
            "Epoch [5 / 10] Train: - accuracy: 0.81, loss: 2.25: 100%|██████████| 61/61 [00:01<00:00, 48.24it/s]\n",
            "Epoch [5 / 10]   Val: - accuracy: 0.79, loss: 2.32: 100%|██████████| 16/16 [00:00<00:00, 58.34it/s]\n",
            "Epoch [6 / 10] Train: - accuracy: 0.82, loss: 2.15: 100%|██████████| 61/61 [00:01<00:00, 48.78it/s]\n",
            "Epoch [6 / 10]   Val: - accuracy: 0.79, loss: 2.29: 100%|██████████| 16/16 [00:00<00:00, 60.08it/s]\n",
            "Epoch [7 / 10] Train: - accuracy: 0.83, loss: 2.09: 100%|██████████| 61/61 [00:01<00:00, 48.92it/s]\n",
            "Epoch [7 / 10]   Val: - accuracy: 0.79, loss: 2.23: 100%|██████████| 16/16 [00:00<00:00, 58.07it/s]\n",
            "Epoch [8 / 10] Train: - accuracy: 0.83, loss: 2.04: 100%|██████████| 61/61 [00:01<00:00, 47.66it/s]\n",
            "Epoch [8 / 10]   Val: - accuracy: 0.79, loss: 2.14: 100%|██████████| 16/16 [00:00<00:00, 53.07it/s]\n",
            "Epoch [9 / 10] Train: - accuracy: 0.84, loss: 1.98: 100%|██████████| 61/61 [00:01<00:00, 47.83it/s]\n",
            "Epoch [9 / 10]   Val: - accuracy: 0.79, loss: 2.11: 100%|██████████| 16/16 [00:00<00:00, 57.62it/s]\n",
            "Epoch [10 / 10] Train: - accuracy: 0.84, loss: 1.93: 100%|██████████| 61/61 [00:01<00:00, 47.70it/s]\n",
            "Epoch [10 / 10]   Val: - accuracy: 0.79, loss: 2.13: 100%|██████████| 16/16 [00:00<00:00, 56.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.6145173041894355,\n",
              "  0.7060473588342443,\n",
              "  0.7935519125683059,\n",
              "  0.805865209471767,\n",
              "  0.8138251366120216,\n",
              "  0.8209653916211292,\n",
              "  0.8279417122040071,\n",
              "  0.8305828779599271,\n",
              "  0.8367941712204005,\n",
              "  0.8399453551912568],\n",
              " [0.6655706521739131,\n",
              "  0.7833152173913044,\n",
              "  0.7872554347826087,\n",
              "  0.7914130434782609,\n",
              "  0.7870380434782609,\n",
              "  0.7937228260869564,\n",
              "  0.7868206521739132,\n",
              "  0.789320652173913,\n",
              "  0.788913043478261,\n",
              "  0.7886956521739129])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0VAKawDV1R8",
        "colab_type": "text"
      },
      "source": [
        "# Mixed models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GDXKsnDDV1R9",
        "colab_type": "text"
      },
      "source": [
        "## Create ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "4-lZMIaUV1R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "models.append(bagging)\n",
        "models.append(forest)\n",
        "models.append(boost)\n",
        "models.append(svc)\n",
        "models.append(NNModel(model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "z7bk3zxeV1R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensemble(models, data):\n",
        "    predicts = pd.DataFrame()\n",
        "    for i, model in enumerate(models):\n",
        "        predicts[i] = model.predict(data)\n",
        "    result = predicts.apply(lambda row: row.value_counts().index[0], axis=1)\n",
        "    return result.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "awEp3SBPV1SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(ensemble(models, val_tf), y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "xkB4XPMDV1SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(ensemble(models, test_tf), y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2kUF-5iV1SJ",
        "colab_type": "text"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7ZIfZjs6V1SJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose your best model\n",
        "final_model = NNModel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "MqOf3QY_V1SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def submission(model, vectorizer, file_name=\"submission.csv\"):\n",
        "    test_data = pd.read_csv(data_folder + \"/test.csv\")\n",
        "    all_lemmatized_texts = lemmatize_texts(test_data.text)\n",
        "    test = vectorizer.transform(all_lemmatized_texts)\n",
        "    submit = pd.DataFrame()\n",
        "    submit['id'] = test_data['id']\n",
        "    submit['target'] = final_model.predict(test)\n",
        "    submit['target'] = submit['target'].astype('int')\n",
        "    submit.to_csv(data_folder + file_name, index=False)\n",
        "    \n",
        "submission(final_model, vectorizer)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}